{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scala_spark playbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/04/24 21:11:52 WARN Utils: Your hostname, C02VD1RGHTDD resolves to a loopback address: 127.0.0.1; using 10.64.185.74 instead (on interface en0)\n",
      "19/04/24 21:11:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "19/04/24 21:11:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "args: [Ljava.lang.String;@27216cd\n",
      "Tracking URI: http://localhost:5000\n",
      "Experiment name: scala_HelloWorld\n",
      "Experiment ID: 5\n",
      "Run ID: 5d44fd992c94459fbcb0a1c56a75db58\n"
     ]
    }
   ],
   "source": [
    "! spark-submit --master local[2] \\\n",
    "  --class org.andre.mlflow.examples.hello.HelloWorld \\\n",
    "  target/mlflow-spark-examples-1.0-SNAPSHOT.jar \\\n",
    "  http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/04/24 21:11:29 WARN Utils: Your hostname, C02VD1RGHTDD resolves to a loopback address: 127.0.0.1; using 10.64.185.74 instead (on interface en0)\n",
      "19/04/24 21:11:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "19/04/24 21:11:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Options:\n",
      "  Tracking URI: http://localhost:5000\n",
      "  token: null\n",
      "  experimentName: scala_DecisionTree\n",
      "  dataPath: ../data/sample_libsvm_data.txt\n",
      "  modelPath: model_sample\n",
      "  maxDepth: 5\n",
      "  maxBins: 5\n",
      "  runOrigin: None\n",
      "Experiment ID: 4\n",
      "Run ID: 1b95d7319070445c9b497e4c51ef3d01\n",
      "runOrigin: None\n",
      "Params:\n",
      "  maxDepth: 5\n",
      "  maxBins: 5\n",
      "Metrics:\n",
      "  RMSE: 0.2970442628930023\n",
      "  isLargerBetter: false\n",
      "Prediction:\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[100,101,102...|\n",
      "|       0.0|  0.0|(692,[121,122,123...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Learned regression tree model:\n",
      " DecisionTreeRegressionModel (uid=dtr_eaa0ec226e98) of depth 2 with 5 nodes\n",
      "  If (feature 407 <= 9.5)\n",
      "   If (feature 243 <= 4.0)\n",
      "    Predict: 1.0\n",
      "   Else (feature 243 > 4.0)\n",
      "    Predict: 0.0\n",
      "  Else (feature 407 > 9.5)\n",
      "   Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! spark-submit --master local[2] \\\n",
    "  --class org.andre.mlflow.examples.decisiontree.TrainDecisionTree \\\n",
    "  target/mlflow-spark-examples-1.0-SNAPSHOT.jar \\\n",
    "  --trackingUri http://localhost:5000 \\\n",
    "  --experimentName scala_DecisionTree \\\n",
    "  --dataPath ../data/sample_libsvm_data.txt \\\n",
    "  --modelPath model_sample --maxDepth 5 --maxBins 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/04/25 14:05:42 WARN Utils: Your hostname, C02VD1RGHTDD resolves to a loopback address: 127.0.0.1; using 10.64.185.74 instead (on interface en0)\n",
      "19/04/25 14:05:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "19/04/25 14:05:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Options:\n",
      "  dataPath: ../data/sample_libsvm_data.txt\n",
      "  tracking URI: null\n",
      "  token: null\n",
      "  runId: 3418ce2004454821b63e2fcff64177f4\n",
      "MLFLOW_TRACKING_URI: http://localhost:5000\n",
      "==== Spark ML\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "|       1.0|  1.0|(692,[158,159,160...|\n",
      "|       1.0|  1.0|(692,[124,125,126...|\n",
      "|       1.0|  1.0|(692,[152,153,154...|\n",
      "|       1.0|  1.0|(692,[151,152,153...|\n",
      "|       0.0|  0.0|(692,[129,130,131...|\n",
      "|       1.0|  1.0|(692,[158,159,160...|\n",
      "|       1.0|  1.0|(692,[99,100,101,...|\n",
      "|       0.0|  0.0|(692,[154,155,156...|\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "==== MLeap\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "|       0.0|  1.0|(692,[158,159,160...|\n",
      "|       0.0|  1.0|(692,[124,125,126...|\n",
      "|       0.0|  1.0|(692,[152,153,154...|\n",
      "|       0.0|  1.0|(692,[151,152,153...|\n",
      "|       0.0|  0.0|(692,[129,130,131...|\n",
      "|       0.0|  1.0|(692,[158,159,160...|\n",
      "|       0.0|  1.0|(692,[99,100,101,...|\n",
      "|       0.0|  0.0|(692,[154,155,156...|\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! spark-submit --class org.andre.mlflow.examples.decisiontree.PredictDecisionTree \\\n",
    "  --master local[2] target/mlflow-spark-examples-1.0-SNAPSHOT.jar \\\n",
    "  --dataPath ../data/sample_libsvm_data.txt  \\\n",
    "  --runId 3418ce2004454821b63e2fcff64177f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
